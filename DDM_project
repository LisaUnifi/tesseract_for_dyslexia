0 - Abstract

Dyslexia is a learning disability in reading and writing. Ad una persona dislessica le 
lettere possono apparire in modo distorto, rispetto a come realmente appaiono.
Allo scopo di migliorare l'esperienza di lettura di persone affette da questa condizione, 
negli anni sono stati sviluppati diversi tipi di font.
In questo lavoro abbiamo deciso di addestrare un OCR, in particolare Tesseract, 
con varie categorie di font, compresi quelli designed per dislessia. Abbiamo poi applicato delle
elaborazioni di immagini simulando le visual processing disorders di soggetti dislessici 
e abbiamo valutato quanto peggiorano le performance di riconoscimento, al variare delle distorsioni.
In questa maniera vogliamo valutare se i font designed per dislessici 
effettivamente riescono ad essere più resilienti rispetto ad altre categorie, tipo serif e sans serif.


1 - Introduction




2 - Fonts

Typefaces play an important role in documents design [20], due to their function regarding readability ad legibility [25]. Research demonstrates that standard typefaces are not as effective for readers with dyslexia as for other readers [12].
Feel more comfortable with reading [12,17]. 
Fig.2 shows the letterforms of dyslexia typefaces compared to a standard typaface, Arial.

Abbiamo così deciso di lavorare su tre categorie di font differenti: serif, sans-serif e dyslexia-designed fonts. La principale caratteristica di un serif font is the presence of an extend off the end of the letterform with a decorative stroke, che rende il testo more formal and readable. Sans-serif fonts do not present these decorative strokes at the end of character and are often considered easier to read in digital mediums, making the experience of reading the most comfortable possible.
Le assunzioni appena fatte sulla facilità di lettura di queste due categorie di font non valgono per i lettori affetti da dislessia. [http://apwspedteam.weebly.com/uploads/2/9/6/7/29672627/dyslexia_font_toolkit.pdf]

Le caratteristiche che rendono un font dyslexia-friendly hanno come fine la riduzione della simmetria presente tra alcune lettere. I readers dislessici spesso hanno difficoltà nella distinzione di certe coppie di lettere, sia perchè fra loro speculari, sia perchè della stessa altezza. Se prendiamo in esempio la b e la d, si osserva che nei font più ricorrenti, e più difficili da leggere per dyslexia readers, una è l'esatto specchio dell'altra. Il fine è quindi riuscire a rompere queste somiglianze modificandone le forme e differenziandole soprattutto tra lettere simili, allargando lo stroke in determinate zone del font o rompendo la continuità della linea. Si ottiene quindi una forma unica per ogni carattere così da rendere più facile il riconoscimento. [https://www.designmantic.com/community/dyslexia-friendly-fonts-for-better-learning.php]

I dieci font che abbiamo usato sono illustrati nella fig.x, raccolti per categoria.

[https://www.dyslexia-reading-well.com/dyslexia-font.html]

[https://www.nhs.uk/conditions/dyslexia/]

[https://www.understood.org/articles/en/what-is-dyslexia]

[https://www.masterclass.com/articles/serif-vs-sans-serif-compared#what-is-a-sans-serif-font]


3 - Dataset creation

Il dataset utilizzato è stato generato a partire da un libro di letteratura inglese, dal quale abbiamo estratto il contenuto. A partire da questo, abbiamo creato un TXT sul quale abbiamo rimosso i metadati e simboli speciali portati dalla conversione dal formato PDF.

Il passo successivo è stato utilizzare LaTex per creare file PDF con i font introdotti nel capitolo precedente. La libreria FONTSPEC ci ha infatti permesso di generare, a partire dallo stesso contenuto informativo, una serie di file PDF iterando sui font da noi specificati. Questa è stata la preparazione necessaria per l'addestramento di Tesseract OCR, per il quale abbiamo bisogno di single line images.

3.1 - Binarization and Segmentation

Per ottenere single line images, dobbiamo suddividere il nostro PDF in pagine singole, che verranno prima binarizzate e successivamente segmentate.
Tramite la libreria Kraken di Python, abbiamo potuto creare le immagini, avendo cura di scegliere i parametri per una corretta segmentazione.
Nello specifico per la binarizzazione è stato necessario fare uno studio sul disegno del font per trovare il parametro di threshold più corretto. Abbiamo empiricamente verificato che font con caratteri molto vicini richiedono un threshold più basso, come ad esempio Times New Roman.
Procedendo con una corretta binarizzazione della pagina, segue anche una corretta identificazione delle connected components che costituiscono la single line. Il tutto si conclude con la segmentazione della pagina in line boxes come desiderato. Le immagini sono state salvate con l'estensione TIFF, poichè questa è una delle estensioni predilette per l'addestramento di Tesseract.

3.2 - Ground Truth Generation

Per poter concludere la fase preliminare della creazione dei dati necessari all'addestramento, abbiamo generato dei file TXT contenenti l'informazione testuale contenuta in ogni single line image, ovvero le ground truths. 
Usando PDFMiner, una libreria di Python e partendo dai PDF precedentemente generati, abbiamo estratto l'informazione testuale di ogni singola linea e la abbiamo associata alla corrispettiva immagine TIFF.


4 - Training

Per il nostro lavoro, abbiamo deciso di produrre un modello per ogni font scelto. Quindi una volta preparato il dataset, con immagini e ground truth, abbiamo individuato Tesseract come lo strumento di cui avvalersi.

4.1 - Tesseract OCR

Abbiamo utilizzato la versione 4.1.1 di Tesseract, fornita di LSTM training {da approfondire...}...

{inserire quantità del dataset e parametri di addestramento}
{se vogliamo possiamo parlare di grandezza di GB e quanto tempo necessario per addestramento}
{anche uso della memoria esterna}
{MAX_ITERATIONS = 100000, PSM=7, RATIO_TRAIN=0.9, LEARNING_RATE=0.002, TARGET_ERROR_RATE=0.01}

[https://github.com/tesseract-ocr/tesstrain]



5 - Image Distortions

Per simulare le distorsioni visive percepite da un soggetto dislessico, abbiamo creato un diverso set di immagini di testo inglese, sulle quali abbiamo applicato alcune distorsioni. 
Nuovamente abbiamo preso l'informazione testuale da un libro di letteratura inglese e abbiamo seguito lo stesso schema di generazione descritto per la creazione del training set, ottenendo così {inserire quantità di test set} e le rispettive ground truth.
Prendendo spunto dall'articolo [], abbiamo deciso di lavorare su tre diverse distorsioni. La nostra decisione è stata quella di applicare 3 diversi parametri di scala per ogni trasformazione al set di immagini appena menzionato.

5.1 - Blurring

Blurring an image is equivalent to reducing the details. This can be done by smoothing the color transition between the pixels.
To accomplish this target, we need to apply a convolution operation of a specialized matrix, called kernel, to the image’s matrix. In this case, we used a gaussian kernel with different parameters to create different grades of blurring. To achieve this, we used the OPENCV Python library.

5.2 - Slant 

To create a slant effect on the images, we use an affine transformation of the same image, where we set different slant angles to produce different scale effects. To achieve this, we used the PILLOW Python library.

5.3 - Superimposition

This kind of effect is when two images are placed one over the other. To create this effect we generate from the original a background and a foreground image. For the first one, we add a white padding on the top and on the left side. For the second one we first convert it from RGB to RGBA, and then we set the opacity of white pixels to zero. Finally we paste them together.
To create different scale of superimposition, we change the padding size, producing a different offset between background and foreground. To achieve this, we used the PILLOW Python library.


6 - Results

We now present the results obtained from our experiments. We first presents the distance metric used to compute the effective difference between two strings of text. In our case, the prediction produced by Tesseract OCR on the image and the respective ground truth.

6.1 - Levenshtein Distance

{...documentation...}

6.2 - Comparison

So we computed the distance between the OCR prediction and the ground truth for every single image. We do this for the unaltered images and also for every image generated from the distortion of the original one. Then we store the results in CSV files. 
The choice of computing the comparison of the unalterated images too, derives from not only to estimate the capacity of predicting the correct results of our models, but also to comprehend how much the model is invariant to the distortions applied.
To achieve this, we also compute the mean value of the distances obtained from our precedent step and we collect them in an other CSV file. We do this for every font and every different distortion parameter.

6.3 - Data results

{immagini e discussione}

7 -  Conclusions


8 - Bibliography